[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "",
    "text": "etielle is a simple, powerful Python library for reshaping nested JSON data, typically from an API, into relational tables that fit your database schema. Think of etielle as a “JSON extractor” that you program with clear instructions: “Go here in the JSON, pull this data, and put it in that table.” The library’s name is a play on ETL (“Extract, Transform, Load”), which is the technical term for this set of operations."
  },
  {
    "objectID": "index.html#why-use-etielle-for-beginners",
    "href": "index.html#why-use-etielle-for-beginners",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Why Use etielle? (For Beginners)",
    "text": "Why Use etielle? (For Beginners)\nJSON data from APIs (Application Program Interfaces—web services that typically return JSON) is often deeply nested and requires complicated parsing. etielle helps by:\n\nDeclaring what you want: Write Python code to describe your tables and how to fill them.\nTraversing nested structures: Walk through arrays-within-dictionaries-within-arrays to any arbitrary depth.\nPerforming arbitrary transformations: Use the provided functions to perform common operations (like getting the key or index of the current item or its parent), or define your own.\nBuilding relationships: Link records across your different output tables and emit ORM relationships or foreign keys.\nBeing beginner-friendly: Everything is type-safe (Python checks your types), composable (build complex things from simple pieces), and easy to debug."
  },
  {
    "objectID": "index.html#learning-path",
    "href": "index.html#learning-path",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Learning Path",
    "text": "Learning Path\n\nStart here: Follow the Quick Start example below to see basic mapping\nUnderstand the pieces: Read Core Concepts to learn about Context, Transforms, and TraversalSpec\nGo deeper: Explore the detailed examples for nesting and merging\nAdvanced features: Check out the docs/ folder for instance emission, relationships, and more"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Installation",
    "text": "Installation\nWe recommend using uv for faster installs, but pip works too.\n\nWith uv (Recommended for Speed)\nFor your project:\nuv add etielle\nFor one-off use:\nuv pip install etielle\n\n\nWith pip\npip install etielle\n\n\nOptional: SQLAlchemy adapter\nIf you plan to bind relationships and flush via SQLAlchemy in one go, install the optional extra:\nuv add \"etielle[sqlalchemy]\"\n\n\nOptional: SQLModel adapter\nIf you plan to bind relationships and flush via SQLModel in one go, install the optional extra:\nuv add \"etielle[sqlmodel]\""
  },
  {
    "objectID": "index.html#quick-start-your-first-mapping",
    "href": "index.html#quick-start-your-first-mapping",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Quick Start: Your First Mapping",
    "text": "Quick Start: Your First Mapping\nLet’s start with a simple example. Suppose you have this JSON:\n\nimport json\n\ndata = {\n  \"users\": [\n    {\"id\": \"u1\", \"name\": \"Alice\", \"posts\": [{\"id\": \"p1\", \"title\": \"Hello\"}, {\"id\": \"p2\", \"title\": \"World\"}]},\n    {\"id\": \"u2\", \"name\": \"Bob\", \"posts\": []}\n  ]\n}\n\nWe want two tables: “users” (id, name) and “posts” (id, user_id, title).\nHere’s the code:\n\nfrom etielle.core import MappingSpec, TraversalSpec, TableEmit, Field  # Core building blocks\nfrom etielle.transforms import get, get_from_parent  # Functions to pull data from JSON\nfrom etielle.executor import run_mapping  # The engine that runs everything\n\n# A TraversalSpec tells etielle how to walk through your JSON. Think of it as\n# giving directions: \"Start at the 'users' key, then loop through each item in that array.\"\n\n# Traverse users array\nusers_traversal = TraversalSpec(\n    path=[\"users\"],  # Path to the array\n    mode=\"auto\",  # Iterate automatically based on container\n    emits=[\n        # The join_keys identify each unique row—like a primary key in a database.\n        # Rows with matching keys will be merged together.\n        TableEmit(\n            table=\"users\",\n            join_keys=[get(\"id\")],  # Unique key for the row\n            fields=[\n                Field(\"id\", get(\"id\")),\n                Field(\"name\", get(\"name\"))\n            ]\n        )\n    ]\n)\n\n# This second traversal is nested: first we navigate to each user,\n# then for each user we go into their posts array using inner_path.\nposts_traversal = TraversalSpec(\n    path=[\"users\"],\n    mode=\"auto\",\n    inner_path=[\"posts\"],  # Nested path inside each user\n    inner_mode=\"auto\",\n    emits=[\n        TableEmit(\n            table=\"posts\",\n            join_keys=[get(\"id\")],\n            fields=[\n                Field(\"id\", get(\"id\")),\n                Field(\"user_id\", get_from_parent(\"id\")),  # Link to parent user\n                Field(\"title\", get(\"title\"))\n            ]\n        )\n    ]\n)\n\nspec = MappingSpec(traversals=[users_traversal, posts_traversal])\nresult = run_mapping(data, spec)\n\n# result is a dict: {\"users\": MappingResult, \"posts\": MappingResult}\n# Each MappingResult has .instances (a dict keyed by join_keys)\n# Let's convert to simple lists for display:\nout = {table: list(mr.instances.values()) for table, mr in result.items()}\nprint(json.dumps(out, indent=2))\n\n{\n  \"users\": [\n    {\n      \"id\": \"u1\",\n      \"name\": \"Alice\"\n    },\n    {\n      \"id\": \"u2\",\n      \"name\": \"Bob\"\n    }\n  ],\n  \"posts\": [\n    {\n      \"id\": \"p1\",\n      \"user_id\": \"u1\",\n      \"title\": \"Hello\"\n    },\n    {\n      \"id\": \"p2\",\n      \"user_id\": \"u1\",\n      \"title\": \"World\"\n    }\n  ]\n}\n\n\nCongrats! You’ve mapped your first JSON."
  },
  {
    "objectID": "index.html#core-concepts-breaking-it-down",
    "href": "index.html#core-concepts-breaking-it-down",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Core Concepts: Breaking It Down",
    "text": "Core Concepts: Breaking It Down\nLet’s explain the building blocks like you’re learning for the first time.\n\n1. Context: Your “Location” in the JSON\nImagine traversing a JSON tree—Context is your GPS:\n\nroot: The entire JSON.\nnode: The current spot (e.g., a user object).\npath: Directions to get here (e.g., (“users”, 0)).\nparent: The previous spot (for looking “up”).\nkey/index: If in a dict/list, the current key or index.\nslots: A notepad for temporary notes.\n\nContexts are created automatically as you traverse and are immutable (unchangeable) for safety.\n\n\n2. Transforms: Smart Data Extractors\nTransforms are like mini-functions that pull values from Context. They’re “lazy”—they don’t run until needed, and they adapt to the current Context.\nExamples:\n\nget(\"name\"): Get “name” from current node → \"Alice\" when node is {\"name\": \"Alice\"}\nget_from_parent(\"id\"): Get “id” from parent context → \"u1\" when processing a post under user u1\nindex(): Current list position → 0 for first item, 1 for second, etc.\nconcat(literal(\"user_\"), get(\"id\")): Combine strings → \"user_u1\"\n\nFull list in the Cheatsheet below.\n\n\n3. TraversalSpec: How to Walk the JSON\nThis says: “Start here, then go deeper if needed, and do this for each item.”\n\npath: Starting path (list of strings, e.g., [“users”]).\nmode: Iteration mode for the outer container: “auto” (default), “items”, or “single”.\ninner_path: Optional deeper path (e.g., [“posts”] for nesting).\ninner_mode: Iteration mode for the inner container: “auto” (default), “items”, or “single”.\nemits: What tables to create from each item.\n\nYou can have multiple Traversals in one MappingSpec—they run independently.\nHere’s a visual representation of how traversals work:\nJSON structure:\nroot\n└── users []                    ← path=[\"users\"]\n    ├── [0] {\"id\": \"u1\", ...}\n    │   └── posts []            ← inner_path=[\"posts\"]\n    │       ├── [0] {\"id\": \"p1\", \"title\": \"Hello\"}\n    │       └── [1] {\"id\": \"p2\", \"title\": \"World\"}\n    └── [1] {\"id\": \"u2\", ...}\n\n\n4. TableEmit and Fields: Building Your Tables\n\ntable: Name of the table.\nfields: List of Field(name, transform) – columns and how to compute them.\njoin_keys: List of transforms for unique row IDs (like primary keys). Same keys across traversals merge rows.\n\n\n\n5. Executor: Running It All\nrun_mapping(json_data, spec) executes everything and returns a dict of tables."
  },
  {
    "objectID": "index.html#detailed-examples",
    "href": "index.html#detailed-examples",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Detailed Examples",
    "text": "Detailed Examples\n\nExample 1: Composite Keys for Merging Data\nMerge user info from two parts of JSON:\n\nspec = MappingSpec(traversals=[\n    TraversalSpec(  # Basic user data\n        path=[\"users\"],\n        mode=\"auto\",\n        emits=[TableEmit(\n            table=\"users\",\n            join_keys=[get(\"id\")],\n            fields=[Field(\"id\", get(\"id\")), Field(\"name\", get(\"name\"))]\n        )]\n    ),\n    TraversalSpec(  # Add email from another section\n        path=[\"profiles\"],\n        mode=\"auto\",\n        emits=[TableEmit(\n            table=\"users\",  # Same table!\n            join_keys=[get(\"user_id\")],  # Matches previous keys\n            fields=[Field(\"email\", get(\"email\"))]\n        )]\n    )\n])\n\nRows with matching keys merge: e.g., add “email” to existing user row.\n\n\nExample 2: Deep Nesting (Arbitrary Depth)\nNo limit to depth—use longer inner_path. The depth parameter controls how many levels up to look:\n\nget_from_parent(\"id\") or depth=1 → immediate parent\nget_from_parent(\"id\", depth=2) → grandparent\nget_from_parent(\"id\", depth=3) → great-grandparent\n\n\nspec = MappingSpec(traversals=[\n    TraversalSpec(\n        path=[\"servers\"],\n        mode=\"auto\",\n        inner_path=[\"channels\", \"messages\", \"reactions\"],  # 3 levels deep!\n        inner_mode=\"auto\",\n        emits=[TableEmit(\n            table=\"reactions\",\n            join_keys=[get_from_parent(\"id\", depth=3), get_from_parent(\"id\", depth=2), get_from_parent(\"id\"), get(\"id\")],\n            fields=[\n                Field(\"server_id\", get_from_parent(\"id\", depth=3)),\n                Field(\"channel_id\", get_from_parent(\"id\", depth=2)),\n                Field(\"message_id\", get_from_parent(\"id\")),\n                Field(\"reaction\", get(\"emoji\"))\n            ]\n        )]\n    )\n])"
  },
  {
    "objectID": "index.html#transform-cheatsheet",
    "href": "index.html#transform-cheatsheet",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Transform Cheatsheet",
    "text": "Transform Cheatsheet\n\nget(path): From current node (dot notation or list, e.g., “user.name” or [“user”, 0]).\nget_from_parent(path, depth=1): From ancestor.\nget_from_root(path): From top-level JSON.\nkey(): Current dict key.\nindex(): Current list index.\nliteral(value): Constant value.\nconcat(*parts): Join strings.\nformat_id(*parts, sep=\"_\"): Join non-empty parts with separator.\ncoalesce(*transforms): First non-None value.\nlen_of(inner): Length of a list/dict/string.\n\nPro Tip: Transforms are lazy—they run in the “context” of where they’re used, making them super flexible.\nTransforms compose naturally:\n\nuser_key = concat(literal(\"user_\"), get(\"id\"))           # \"user_123\"\nfull_name = concat(get(\"first\"), literal(\" \"), get(\"last\"))  # \"Alice Smith\""
  },
  {
    "objectID": "index.html#common-mistakes",
    "href": "index.html#common-mistakes",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Common Mistakes",
    "text": "Common Mistakes\n\nEmpty results?\n\nCheck your path matches the JSON structure exactly\nVerify the data type at that path matches expectations\n\nMissing parent data?\n\nCheck the depth parameter in get_from_parent()\nEnsure the parent context exists in your traversal\n\nDuplicate or missing rows?\n\nVerify join_keys are unique for each row\nCheck that join_keys don’t contain None values (these rows are skipped)"
  },
  {
    "objectID": "index.html#advanced-topics",
    "href": "index.html#advanced-topics",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nLazy Evaluation: Transforms don’t compute until executed, adapting to the current spot in JSON.\nCustom Transforms: Define your own functions that take Context and return values.\nRow Merging Rules: Last write wins for duplicate fields; missing keys skip rows.\nField selectors: Type-safe field references. See Field selectors.\nInstance emission: Build Pydantic/TypedDict/ORM instances directly instead of dicts. See Instance emission.\nMerge policies: Sum/append/min/max instead of overwrite when multiple traversals update the same field. See Merge policies.\nError reporting: Per-key diagnostics in results. See Error reporting.\nRelationships without extra round trips: Bind in-memory, flush once. See Relationships and SQLAlchemy adapter.\nPerformance: Efficient for large JSON; traversals are independent."
  },
  {
    "objectID": "index.html#roadmap-ideas",
    "href": "index.html#roadmap-ideas",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Roadmap Ideas",
    "text": "Roadmap Ideas\n\nDatabase integrations (e.g., SQLAlchemy).\nMore examples and benchmarks.\nVisual mapping tools."
  },
  {
    "objectID": "index.html#glossary",
    "href": "index.html#glossary",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "Glossary",
    "text": "Glossary\n\nContext: Your current position while traversing the JSON tree\nTransform: A function that extracts values from a Context\nTraversal: Instructions for walking through part of the JSON\nEmit: Creating a table row from the current context\nJoin keys: Values that uniquely identify a row (like primary keys)\nDepth: How many parent levels to traverse upward"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "etielle: Declarative JSON-to-Relational Mapping in Python",
    "section": "License",
    "text": "License\nMIT\nNeed help? Open an issue on GitHub!"
  },
  {
    "objectID": "docs/relationships.html",
    "href": "docs/relationships.html",
    "title": "Relationship building (no extra DB round trips)",
    "section": "",
    "text": "What you’ll learn: How to build parent-child relationships in memory and flush once, avoiding N+1 database queries.\nPrerequisites: Understanding of InstanceEmit and composite keys.\nBuild relationships in-memory using composite keys, then flush once. This avoids per-row database round trips.\n\nMany-to-one via relationship keys\nHere’s how etielle builds relationships without database round trips:\n\nCompute keys: Walk through your JSON again to compute which child belongs to which parent\nStore in sidecar: Keep these relationships separate from your instances (in a “sidecar” dict)\nBind in memory: Link child objects to parent objects using Python references\nFlush once: Save everything to the database in one operation\n\nThis avoids the typical ORM pattern of “insert parent, get ID, insert child with foreign key” which requires multiple queries.\n\n\nExample structure\nJSON:\n{\n  \"users\": [\n    {\"id\": \"u1\", \"posts\": [\n      {\"id\": \"p1\", \"title\": \"Hello\"},\n      {\"id\": \"p2\", \"title\": \"World\"}\n    ]}\n  ]\n}\n\nIn memory after mapping:\nUser(id=\"u1\")\nPost(id=\"p1\", user=None)  ← We need to link this\nPost(id=\"p2\", user=None)  ← And this\n\nAfter bind_many_to_one:\nUser(id=\"u1\")\nPost(id=\"p1\", user=&lt;User u1&gt;)  ← Now linked!\nPost(id=\"p2\", user=&lt;User u1&gt;)  ← Now linked!\n\n\nComplete example\n\n# Using the models, emits, mapping, and root from above\n\nrelationships = [\n    ManyToOneSpec(\n        child_table=\"posts\",\n        parent_table=\"users\",\n        attr=\"user\",\n        child_to_parent_key=[get_from_parent(\"id\")],\n    )\n]\n\nresults = run_mapping(root, mapping)\nsidecar = compute_relationship_keys(root, mapping.traversals, relationships)\nbind_many_to_one(results, relationships, sidecar)\nprint(sorted([(p.id, p.user.id if p.user else None) for p in results[\"posts\"].instances.values()]))\n\n[('p1', 'u1'), ('p2', 'u1')]\n\n\n\n\nBehavior\n\nParent indices are built from finalized instances per table.\nMissing parents aggregate clear errors (optional raise).\nNo mutation of domain objects during key computation (keys stored in sidecar map).\n\nFor a complete SQLAlchemy integration example with automatic flushing, see SQLAlchemy adapter.\n\n\nSee also\n\nSQLAlchemy adapter - Full integration with SQLAlchemy ORM\nInstance emission - Creating the instances that relationships link"
  },
  {
    "objectID": "docs/sqlalchemy-adapter.html",
    "href": "docs/sqlalchemy-adapter.html",
    "title": "SQLAlchemy & SQLModel adapters",
    "section": "",
    "text": "What you’ll learn: How to efficiently load mapped data into SQLAlchemy or SQLModel with one-shot flushing.\nPrerequisites: Understanding of relationships (see Relationships).\nThese adapters build on the relationship system described in Relationships. Read that first if you’re not familiar with ManyToOneSpec.\nBind relationships and flush once using the provided adapter utilities. Both adapters work identically—use whichever ORM you prefer.\n\nWhen to use these adapters\nUse bind_and_flush when:\n\nLoading data from APIs into a SQLAlchemy database\nYou have parent-child relationships (users → posts, orders → items, etc.)\nYou want to minimize database round trips\nYou’re doing bulk ETL operations\n\nUse install_before_flush_binder when:\n\nYou need fine-grained control over transactions\nYou want to add additional logic before/after the flush\nYou’re integrating with existing SQLAlchemy code that manages sessions\n\n\n\nInstallation\nInstall the optional extra for your preferred ORM:\n\nSQLAlchemySQLModel\n\n\nuv add \"etielle[sqlalchemy]\"\n\n\nuv add \"etielle[sqlmodel]\"\n\n\n\n\n\nWhat is one-shot bind and flush?\nTraditional ORM approach (multiple database round trips):\n\nInsert parent record → database assigns ID\nQuery to get the ID back\nInsert child record with foreign key → repeat for each child\nResult: N+1 queries (or worse)\n\netielle one-shot approach (single flush):\n\nCreate all parent instances in memory\nCreate all child instances in memory\nLink children to parents using Python object references\nCall session.flush() once → SQLAlchemy inserts everything and handles foreign keys\nResult: 1 database operation\n\nThis is much faster for bulk ETL operations.\n\n\nOne-shot bind and flush\n\nSQLAlchemySQLModel\n\n\n\n# Not shown: setup of database/models/emits/mapping/relationships\n\nfrom etielle.adapters.sqlalchemy_adapter import bind_and_flush\n\nresults = bind_and_flush(\n    session,\n    root=data,\n    mapping=mapping,\n    relationships=relationships,\n    add_all_instances=True,\n)\n\nprint(len(results[\"users\"].instances), len(results[\"posts\"].instances))\n\n2 2\n\n\n\n\n\nfrom typing import Any, Dict\nfrom sqlmodel import SQLModel, Field, Relationship, Session, create_engine, select\nfrom etielle.core import MappingSpec, TraversalSpec\nfrom etielle.transforms import get\nfrom etielle.instances import InstanceEmit, FieldSpec, TypedDictBuilder\nfrom etielle.relationships import ManyToOneSpec\n\n\nclass User(SQLModel, table=True):\n    __tablename__ = \"users\"\n    id: str = Field(primary_key=True)\n    name: str\n    posts: list[\"Post\"] = Relationship(back_populates=\"user\")\n\n\nclass Post(SQLModel, table=True):\n    __tablename__ = \"posts\"\n    id: str = Field(primary_key=True)\n    title: str\n    user_id: str | None = Field(default=None, foreign_key=\"users.id\")\n    user: User | None = Relationship(back_populates=\"posts\")\n\n\ndef _user_factory(payload: Dict[str, Any]) -&gt; User:\n    return User(id=str(payload[\"id\"]), name=str(payload.get(\"name\", \"\")))\n\n\ndef _post_factory(payload: Dict[str, Any]) -&gt; Post:\n    return Post(id=str(payload[\"id\"]), title=str(payload.get(\"title\", \"\")))\n\n\nengine = create_engine(\"sqlite+pysqlite:///:memory:\", future=True)\nSQLModel.metadata.create_all(engine)\nsession = Session(engine)\n\n# Same data, emits, mapping, and relationships as SQLAlchemy example\ndata = {\n    \"users\": [\n        {\"id\": \"u1\", \"name\": \"Alice\"},\n        {\"id\": \"u2\", \"name\": \"Bob\"},\n    ],\n    \"posts\": [\n        {\"id\": \"p1\", \"title\": \"Hello\", \"user_id\": \"u1\"},\n        {\"id\": \"p2\", \"title\": \"World\", \"user_id\": \"u2\"},\n    ],\n}\n\nusers_emit = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=\"id\", transform=get(\"id\")),\n        FieldSpec(selector=\"name\", transform=get(\"name\")),\n    ],\n    builder=TypedDictBuilder(_user_factory),\n)\n\nposts_emit = InstanceEmit[Post](\n    table=\"posts\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=\"id\", transform=get(\"id\")),\n        FieldSpec(selector=\"title\", transform=get(\"title\")),\n    ],\n    builder=TypedDictBuilder(_post_factory),\n)\n\nmapping = MappingSpec(\n    traversals=[\n        TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[users_emit]),\n        TraversalSpec(path=[\"posts\"], mode=\"auto\", emits=[posts_emit]),\n    ]\n)\n\nrelationships = [\n    ManyToOneSpec(\n        child_table=\"posts\",\n        parent_table=\"users\",\n        attr=\"user\",\n        child_to_parent_key=[get(\"user_id\")],\n        required=True,\n    )\n]\n\n\nfrom etielle.adapters.sqlmodel_adapter import bind_and_flush\n\nresults = bind_and_flush(\n    session,\n    root=data,\n    mapping=mapping,\n    relationships=relationships,\n    add_all_instances=True,\n)\n\nprint(len(results[\"users\"].instances), len(results[\"posts\"].instances))\n\n2 2\n\n\n\n\n\n\n\nPerformance notes\nFor 1000 users with 10 posts each:\nTraditional approach:\n\n1000 INSERT for users\n10,000 INSERT for posts (each needing parent’s ID)\nTotal: 11,000+ database operations\n\nOne-shot approach:\n\n1 bulk INSERT for users (1000 rows)\n1 bulk INSERT for posts (10,000 rows)\nTotal: 2 database operations\n\nThe one-shot approach is typically 10-100x faster depending on your database and network latency.\n\n\nBefore-flush hook\nInstall a one-shot before_flush binder when you want to control transaction boundaries yourself.\n\nSQLAlchemySQLModel\n\n\n\nfrom etielle.adapters.sqlalchemy_adapter import install_before_flush_binder\n\n# Fresh session for demo\nsession = Session(engine)\ninstall_before_flush_binder(\n    session,\n    root=data,\n    mapping=mapping,\n    relationships=relationships,\n)\n\n# Trigger flush to execute the binder\nsession.flush()\nfrom sqlalchemy import select\nprint(\n    len(session.execute(select(User)).scalars().all()),\n    len(session.execute(select(Post)).scalars().all()),\n)\n\n2 2\n\n\n\n\n\nfrom etielle.adapters.sqlmodel_adapter import install_before_flush_binder\n\nsession = Session(engine)\ninstall_before_flush_binder(\n    session,\n    root=data,\n    mapping=mapping,\n    relationships=relationships,\n)\n\n# Trigger flush to execute the binder\nsession.flush()\nprint(\n    len(session.exec(select(User)).all()),\n    len(session.exec(select(Post)).all()),\n)\n\n2 2\n\n\n\n\n\n\n\nNotes\n\nAutoflush is temporarily disabled during the one-shot flow to avoid early inserts.\nInstances are added and flushed once; ORMs populate FKs automatically via relationships.\n\n\n\nSee also\n\nRelationships - Understanding relationship specs and binding\nInstance emission - Creating ORM instances"
  },
  {
    "objectID": "docs/error-reporting.html",
    "href": "docs/error-reporting.html",
    "title": "Error reporting and DX",
    "section": "",
    "text": "What you’ll learn: How to interpret error dictionaries and debug mapping failures.\nWhen to read this: When your mapping produces empty results or unexpected errors.\nThe executor aggregates errors with precise table/key context and returns them alongside instances in MappingResult.\n\nResult shape\nfrom etielle.core import MappingResult\n\n# MappingResult[T]\n# - instances: Dict[tuple, T]\n# - update_errors: Dict[tuple, list[str]]\n# - finalize_errors: Dict[tuple, list[str]]\n# - stats: Dict[str, int]\n\n\nWhat to do with errors\nWhen your mapping produces unexpected results, check the error dictionaries:\nUpdate errors indicate problems during field updates:\n\nUnknown field names: You referenced a field that doesn’t exist on your model\n\nFix: Check spelling, or add the field to your model\nThe error message includes suggestions for similar field names\n\nType mismatches: A merge policy expected a number but got a string\n\nFix: Ensure your transforms return the correct type\n\nMerge policy failures: The policy couldn’t combine values\n\nFix: Check that the field is initialized correctly in your model\n\n\nFinalize errors indicate validation failures:\n\nMissing required fields: Your model requires a field but it wasn’t set\n\nFix: Add a FieldSpec for that field, or make it optional in your model\n\nValidation errors: Pydantic validation failed (wrong type, out of range, etc.)\n\nFix: Check your transform outputs match your model’s field types\n\n\n\n\nUpdate vs finalize errors\n\nUpdate errors: recorded during incremental field updates (e.g., per-field type checks, unknown fields, merge-policy failures).\nFinalize errors: recorded when builders validate/construct final instances.\n\n\n\nStrictness\n\nstrict_fields=True (default) checks unknown fields against builder.known_fields().\nstrict_mode=\"fail_fast\" will raise on unknown fields instead of collecting.\n\n\n\nUnknown field suggestions\nWhen using string field names, the executor suggests closest matches using difflib.get_close_matches.\n\n\nDebugging workflow\n\nCheck stats first: Look at result[\"table\"].stats to see counts\nprint(result[\"users\"].stats)\n# {\"num_instances\": 10, \"num_update_errors\": 2, \"num_finalize_errors\": 0}\nInspect update errors: If num_update_errors &gt; 0, check which keys had problems\nfor key, errors in result[\"users\"].update_errors.items():\n    print(f\"Row {key} had update errors: {errors}\")\nInspect finalize errors: If num_finalize_errors &gt; 0, check validation issues\nfor key, errors in result[\"users\"].finalize_errors.items():\n    print(f\"Row {key} failed validation: {errors}\")\nLook at successful instances: Compare working rows with error rows\nprint(f\"Successfully created {len(result['users'].instances)} instances\")\n\n\n\nExample\n\n# Not shown: setup of root/emit/mapping\n\nfrom etielle.executor import run_mapping\n\nresults = run_mapping(root, mapping)\nusers = results[\"users\"]\nprint(users.stats)\nprint(users.update_errors)\nprint(users.finalize_errors)\n\n{'num_instances': 0, 'num_update_errors': 1, 'num_finalize_errors': 1}\n{('u1',): [\"table=users key=('u1',) field emali: unknown field; did you mean email?\"]}\n{('u1',): [\"table=users key=('u1',) 1 validation error for User\\nemail\\n  Field required [type=missing, input_value={'id': 'u1'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\"]}\n\n\nThe output shows what actual error messages look like:\n# Example output:\nresult[\"users\"].update_errors\n# {\n#   ('u1',): [\n#     \"Unknown field 'emali' for table 'users'. Did you mean: 'email'?\"\n#   ]\n# }\n\nresult[\"users\"].finalize_errors\n# {\n#   ('u1',): [\n#     \"Field 'email' is required but was not set\"\n#   ]\n# }\n\n\nSee also\n\nField selectors - How to avoid typos with type-safe selectors\nInstance emission - Understanding update vs finalize errors"
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "Make release workflow ff after publish (506d3c8)\n\n\n\n\n\nAdd backticks around code (e251f3f)\nAll documentation code runs (61dbb24)\nDocumentation website (8019c14)\nExample code triggers errors (b12093e)\nFix header text color (69ab9d4)\nPrint mapping result (1ef1164)\n\n\n\n\n\nSimplify iteration API (25e1c17)\n\n\n\n\n\n\n\n\nSqlalchemy adapter (3ac07a1)\n\n\n\n\n\n\n\n\nMutation-based emit (21dbbe6)\n\n\n\n\n\n\n\n\nError reporting (10657ec)\nInstance emission adapter (4c02de0)\n\n\n\n\n\n\n\n\nImplement field selectors API (e099dbe)\n\n\n\n\n\n\n\n\nConfigure pyproject version stamping (49c4e07)\n\n\n\n\n\n\n\n\nMake release dependent on test (b377958)\n\n\n\n\n\n\n\n\nCorrectly use PyPi env for publish job (2dd6cea)\n\n\n\n\n\n\n\n\nRun build in PSR container (6c359c6)\n\n\n\n\n\n\n\n\nRestore build step (4250642)\n\n\n\n\n\n\n\n\nGate artifact upload (5e5bda1)\n\n\n\n\n\n\n\n\nActions-compliant root path (251d553)\nAdd missing semantic release config (f6235d4)\nSemantic release version mismatch (3dbf9a0)\nUse semantic release’s built-in committer (6681c31)"
  },
  {
    "objectID": "CHANGELOG.html#v2.0.0-2025-10-19",
    "href": "CHANGELOG.html#v2.0.0-2025-10-19",
    "title": "Changelog",
    "section": "",
    "text": "Make release workflow ff after publish (506d3c8)\n\n\n\n\n\nAdd backticks around code (e251f3f)\nAll documentation code runs (61dbb24)\nDocumentation website (8019c14)\nExample code triggers errors (b12093e)\nFix header text color (69ab9d4)\nPrint mapping result (1ef1164)\n\n\n\n\n\nSimplify iteration API (25e1c17)"
  },
  {
    "objectID": "CHANGELOG.html#v1.4.0-2025-10-15",
    "href": "CHANGELOG.html#v1.4.0-2025-10-15",
    "title": "Changelog",
    "section": "",
    "text": "Sqlalchemy adapter (3ac07a1)"
  },
  {
    "objectID": "CHANGELOG.html#v1.3.0-2025-10-14",
    "href": "CHANGELOG.html#v1.3.0-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Mutation-based emit (21dbbe6)"
  },
  {
    "objectID": "CHANGELOG.html#v1.2.0-2025-10-14",
    "href": "CHANGELOG.html#v1.2.0-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Error reporting (10657ec)\nInstance emission adapter (4c02de0)"
  },
  {
    "objectID": "CHANGELOG.html#v1.1.0-2025-10-14",
    "href": "CHANGELOG.html#v1.1.0-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Implement field selectors API (e099dbe)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.6-2025-10-14",
    "href": "CHANGELOG.html#v1.0.6-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Configure pyproject version stamping (49c4e07)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.5-2025-10-14",
    "href": "CHANGELOG.html#v1.0.5-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Make release dependent on test (b377958)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.4-2025-10-14",
    "href": "CHANGELOG.html#v1.0.4-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Correctly use PyPi env for publish job (2dd6cea)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.3-2025-10-14",
    "href": "CHANGELOG.html#v1.0.3-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Run build in PSR container (6c359c6)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.2-2025-10-14",
    "href": "CHANGELOG.html#v1.0.2-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Restore build step (4250642)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.1-2025-10-14",
    "href": "CHANGELOG.html#v1.0.1-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Gate artifact upload (5e5bda1)"
  },
  {
    "objectID": "CHANGELOG.html#v1.0.0-2025-10-14",
    "href": "CHANGELOG.html#v1.0.0-2025-10-14",
    "title": "Changelog",
    "section": "",
    "text": "Actions-compliant root path (251d553)\nAdd missing semantic release config (f6235d4)\nSemantic release version mismatch (3dbf9a0)\nUse semantic release’s built-in committer (6681c31)"
  },
  {
    "objectID": "docs/instance-emission.html",
    "href": "docs/instance-emission.html",
    "title": "Instance emission (Pydantic, TypedDict, ORM)",
    "section": "",
    "text": "What you’ll learn: How to emit Pydantic models or ORM objects directly instead of plain dicts, enabling validation and type safety.\nPrerequisites: Basic understanding of TableEmit and Field from the README Quick Start.\n\nWhat is instance emission?\nInstead of getting back plain dicts from your mapping, you can tell etielle to create your Pydantic models, TypedDicts, or ORM objects directly.\nThis means you get:\n\nValidated data: Pydantic validates as it builds\nType safety: Your IDE knows the exact type of each instance\nORM integration: Create database objects without manual conversion\n\nProgressive construction means you can have multiple traversals updating the same instance. For example:\n\nTraversal 1 sets id and name from users array\nTraversal 2 adds email from profiles array\nBoth updates merge into one User instance with matching join_keys\n\n\n\nTableEmit vs. InstanceEmit\nWith TableEmit (basic approach):\n\nfrom etielle.core import MappingSpec, TraversalSpec, TableEmit, Field\nfrom etielle.transforms import get\nfrom etielle.executor import run_mapping\n\ndata = {\"users\": [{\"id\": \"u1\", \"email\": \"alice@example.com\"}]}\n\nspec = MappingSpec(traversals=[TraversalSpec(\n    path=[\"users\"],\n    mode=\"auto\",\n    emits=[TableEmit(\n        table=\"users\",\n        join_keys=[get(\"id\")],\n        fields=[Field(\"id\", get(\"id\")), Field(\"email\", get(\"email\"))]\n    )]\n)])\nresult = run_mapping(data, spec)\n# result[\"users\"].instances = {(\"u1\",): {\"id\": \"u1\", \"email\": \"alice@example.com\"}}\n#                                        ↑ plain dict\n\nWith InstanceEmit (typed approach):\n\nfrom etielle.core import MappingSpec, TraversalSpec, field_of\nfrom etielle.transforms import get\nfrom etielle.instances import InstanceEmit, FieldSpec, PydanticBuilder\nfrom etielle.executor import run_mapping\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: str\n    email: str\n\ndata = {\"users\": [{\"id\": \"u1\", \"email\": \"alice@example.com\"}]}\n\nspec = MappingSpec(traversals=[TraversalSpec(\n    path=[\"users\"],\n    mode=\"auto\",\n    emits=[InstanceEmit[User](\n        table=\"users\",\n        join_keys=[get(\"id\")],\n        builder=PydanticBuilder(User),\n        fields=[\n            FieldSpec(selector=field_of(User, lambda u: u.id), transform=get(\"id\")),\n            FieldSpec(selector=field_of(User, lambda u: u.email), transform=get(\"email\")),\n        ]\n    )]\n)])\nresult = run_mapping(data, spec)\n# result[\"users\"].instances = {(\"u1\",): User(id=\"u1\", email=\"alice@example.com\")}\n#                                        ↑ Pydantic model instance\n\n\n\nBuilders\n\nfrom etielle.instances import InstanceEmit, FieldSpec, PydanticBuilder, TypedDictBuilder\nfrom etielle.transforms import get\nfrom etielle.core import MappingSpec, TraversalSpec, field_of\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: str\n    email: str\n\nemit = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=field_of(User, lambda u: u.id), transform=get(\"id\")),\n        FieldSpec(selector=field_of(User, lambda u: u.email), transform=get(\"email\")),\n    ],\n    builder=PydanticBuilder(User),\n)\n\n# Minimal runnable demo\nroot = {\"users\": [{\"id\": \"u1\", \"email\": \"alice@example.com\"}]}\nmapping = MappingSpec(traversals=[TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[emit])])\nfrom etielle.executor import run_mapping\nres = run_mapping(root, mapping)\nprint(sorted([(k, v.email) for k, v in res[\"users\"].instances.items()]))\n\n[(('u1',), 'alice@example.com')]\n\n\nTypedDict without Pydantic:\n\nfrom typing import TypedDict\n\nclass UserTD(TypedDict):\n    id: str\n    email: str\n\nemit_td = InstanceEmit[UserTD](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=\"id\", transform=get(\"id\")),\n        FieldSpec(selector=\"email\", transform=get(\"email\")),\n    ],\n    builder=TypedDictBuilder(lambda d: UserTD(**d)),\n)\n\n# Minimal runnable demo\nroot = {\"users\": [{\"id\": \"u1\", \"email\": \"alice@example.com\"}]}\nmapping = MappingSpec(traversals=[TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[emit_td])])\nfrom etielle.executor import run_mapping\nres = run_mapping(root, mapping)\nprint(list(res[\"users\"].instances.values()))\n\n[{'id': 'u1', 'email': 'alice@example.com'}]\n\n\n\n\nChoosing a builder\n\nPydanticBuilder(Model): Use for Pydantic models with validation\nPydanticPartialBuilder(Model): Use when some fields might be missing (creates partial models)\nTypedDictBuilder(factory): Use for plain dicts or when you don’t want Pydantic\nCustom builder: Implement the builder protocol for ORM objects or custom types\n\n\n\nStrictness and error collection\nBuilders collect update-time and finalize-time errors; the executor returns them in MappingResult per table.\n\nfrom etielle.executor import run_mapping\n\nresult = run_mapping(root_err, mapping_err)\nmr = result[\"users\"]\nprint(mr.update_errors)\nprint(mr.finalize_errors)\n\n{('u1',): [\"table=users key=('u1',) field emali: unknown field; did you mean email?\"]}\n{('u1',): [\"table=users key=('u1',) 1 validation error for User\\nemail\\n  Field required [type=missing, input_value={'id': 'u1'}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\"]}\n\n\n\n\nMerge policies\nBy default, if two traversals update the same field, the last write wins. You can change this behavior—see Merge policies for details.\n\n\nReference\n\nInstanceEmit[T]\nFieldSpec[T]\nPydanticBuilder, PydanticPartialBuilder, TypedDictBuilder\n\n\n\nSee also\n\nField selectors - Type-safe field references for InstanceEmit\nMerge policies - Controlling how repeated updates combine\nError reporting - Debugging instance construction failures"
  },
  {
    "objectID": "docs/field-selectors.html",
    "href": "docs/field-selectors.html",
    "title": "Field selectors",
    "section": "",
    "text": "What you’ll learn: How to use type-safe field references instead of strings, when to choose each approach, and how to catch typos at type-check time.\nField selectors let you refer to model fields in a way static type checkers can verify, while the runtime resolves the field name without reflection.\n\nWhy use field selectors?\nField selectors provide three key benefits over plain strings:\n\nIDE autocomplete: Your editor will suggest available fields as you type\nType-check time errors: Typos are caught before running your code\nRefactoring safety: Renaming a field updates all selector references automatically\n\nIf you’re working with plain dicts or don’t use type checkers, plain strings work fine.\n\n\nWhat is a field selector?\nUse field_of(Model, lambda m: m.field) to produce the string field name at runtime. Type checkers validate the lambda, catching typos early.\n\nfrom etielle.core import field_of\n\nclass User:\n    id: str\n    email: str\n\nprint(field_of(User, lambda u: u.email))\n\nemail\n\n\n\n\nConstraints (enforced at runtime)\n\nExactly one attribute access must occur.\nNo method calls, no indexing, no chained attributes.\n\n\nfrom etielle.core import field_of\n\nclass Model:\n    x: int\n\n# OK\nprint(field_of(Model, lambda m: m.x))\n\n# Raises ValueError (method call)\ntry:\n    field_of(Model, lambda m: m.x.__str__())\nexcept ValueError:\n    pass\n\n# Raises ValueError (chained)\ntry:\n    field_of(Model, lambda m: m.x.real)\nexcept ValueError:\n    pass\n\nx\n\n\n\n\nWhen to use field selectors vs. strings\nUse field_of() selectors when:\n\nWorking with Pydantic models, dataclasses, or typed classes\nUsing a type checker (mypy, pyright)\nWant IDE autocomplete and refactoring support\n\nUse plain string field names when:\n\nWorking with plain dicts or dynamic data\nPrototyping quickly without types\nField names are computed dynamically at runtime\n\n\n\nUsing selectors in instance emission\nSelectors are used with FieldSpec inside InstanceEmit. They are resolved against the builder’s model.\n\nfrom etielle.core import MappingSpec, TraversalSpec, field_of\nfrom etielle.transforms import get\nfrom etielle.instances import InstanceEmit, FieldSpec, PydanticBuilder\nfrom pydantic import BaseModel\n\nclass UserModel(BaseModel):\n    id: str\n    email: str\n\nemit = InstanceEmit[UserModel](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=field_of(UserModel, lambda u: u.id), transform=get(\"id\")),\n        FieldSpec(selector=field_of(UserModel, lambda u: u.email), transform=get(\"email\")),\n    ],\n    builder=PydanticBuilder(UserModel),\n)\n\nIf you use a builder without a model attribute, pass string field names instead of selectors.\n\n\nComparison: Selectors vs. Strings\nHere’s a side-by-side comparison showing the tradeoffs:\n\nfrom etielle.instances import InstanceEmit, FieldSpec, PydanticBuilder\nfrom etielle.core import field_of\nfrom etielle.transforms import get\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: str\n    email: str\n\n# With field selectors (type-safe):\nemit_safe = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=field_of(User, lambda u: u.id), transform=get(\"id\")),\n        FieldSpec(selector=field_of(User, lambda u: u.emial), transform=get(\"email\")),  # ❌ Type checker catches typo!\n    ],\n    builder=PydanticBuilder(User),\n)\n\n# With plain strings (more flexible, less safe):\nemit_strings = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=\"id\", transform=get(\"id\")),\n        FieldSpec(selector=\"emial\", transform=get(\"email\")),  # ⚠️ Caught at runtime only (with strict_fields=True)\n    ],\n    builder=PydanticBuilder(User),\n)\n\n\n\nBackwards-compat strings, with strict validation\nString field names remain supported. When strict_fields=True (default), unknown fields are recorded with helpful suggestions, and you can opt into strict_mode=\"fail_fast\" to raise immediately.\n\nfrom etielle.transforms import get\nfrom etielle.instances import InstanceEmit, FieldSpec, TypedDictBuilder\n\nemit = InstanceEmit[dict](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=\"emali\", transform=get(\"email\")),  # typo on purpose\n    ],\n    builder=TypedDictBuilder(lambda d: d),\n    strict_fields=True,\n    # strict_mode=\"fail_fast\",  # enable to raise instead of collect\n)\n\n\n\nReference\n\netielle.core.field_of(model, selector) → str field name\nFieldSpec[T](selector: Callable[[T], Any] | str, transform)\nResolved through builders with a model (e.g., PydanticBuilder).\n\n\n\nSee also\n\nInstance emission - Where field selectors are most commonly used\nError reporting - How unknown field errors are reported"
  },
  {
    "objectID": "docs/merge-policies.html",
    "href": "docs/merge-policies.html",
    "title": "Merge policies (mutation-based emit)",
    "section": "",
    "text": "What you’ll learn: How to control how repeated updates combine (sum, append, min/max) instead of overwriting.\nPrerequisites: Understanding of InstanceEmit (see Instance emission).\nControl how repeated updates to the same field are combined when multiple traversals contribute to one instance.\n\nWhy merge policies?\nDefault behavior (last-write-wins): When multiple traversals write to the same field on the same instance, the second write overwrites the first.\nExample:\n\nTraversal 1 sets user.status = \"active\"\nTraversal 2 sets user.status = \"premium\"\nResult: user.status = \"premium\" (last write wins)\n\nWith merge policies: You can change this behavior to sum numbers, append to lists, take minimum/maximum values, etc.\n\n\nAvailable policies\n\n\n\n\n\n\n\n\nPolicy\nBehavior\nUse case\n\n\n\n\nAddPolicy()\nAdds numbers together\nCounters, sums, totals\n\n\nAppendPolicy()\nAppends single items to list\nCollecting individual tags/flags\n\n\nExtendPolicy()\nExtends list with another list\nMerging lists from different sources\n\n\nMinPolicy()\nKeeps minimum value\nFinding earliest date, lowest score\n\n\nMaxPolicy()\nKeeps maximum value\nFinding latest date, highest score\n\n\nFirstNonNullPolicy()\nKeeps first non-null value\nFallback defaults\n\n\n\n\n\nSimple example: Counting with AddPolicy\n\nfrom etielle.instances import InstanceEmit, FieldSpec, PydanticBuilder, AddPolicy\nfrom etielle.transforms import get, literal\nfrom etielle.core import MappingSpec, TraversalSpec\nfrom etielle.executor import run_mapping\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: str\n    login_count: int = 0\n\n# This emit increments login_count each time it's called\nemit = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=\"id\", transform=get(\"id\")),\n        FieldSpec(selector=\"login_count\", transform=literal(1)),  # Add 1 each time\n    ],\n    builder=PydanticBuilder(User),\n    policies={\"login_count\": AddPolicy()},  # Sum instead of overwrite\n)\n\n# If two traversals emit for the same user:\n# Traversal 1: login_count += 1  → 1\n# Traversal 2: login_count += 1  → 2\n# Result: user.login_count = 2\n\nroot = {\"users\": [{\"id\": \"u1\"}]}\nmapping = MappingSpec(traversals=[\n    TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[emit]),\n    TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[emit]),  # Same emit twice\n])\n\nres = run_mapping(root, mapping)\nu = list(res[\"users\"].instances.values())[0]\nprint(f\"login_count: {u.login_count}\")  # Prints: login_count: 2\n\nlogin_count: 2\n\n\n\n\nExample: Multiple policies\n\nfrom etielle.instances import InstanceEmit, FieldSpec, PydanticBuilder, AddPolicy, AppendPolicy\nfrom etielle.transforms import get, literal\nfrom etielle.core import field_of, MappingSpec, TraversalSpec\nfrom etielle.executor import run_mapping\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: str\n    login_count: int\n    tags: list[str]\n\nemit = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=field_of(User, lambda u: u.id), transform=get(\"id\")),\n        FieldSpec(selector=field_of(User, lambda u: u.login_count), transform=literal(1)),\n        FieldSpec(selector=field_of(User, lambda u: u.tags), transform=literal(\"alpha\")),\n    ],\n    builder=PydanticBuilder(User),\n    policies={\n        \"login_count\": AddPolicy(),\n        \"tags\": AppendPolicy(),\n    },\n)\n\nroot = {\"users\": [{\"id\": \"u1\"}]}\nemit2 = InstanceEmit[User](\n    table=\"users\",\n    join_keys=[get(\"id\")],\n    fields=[\n        FieldSpec(selector=field_of(User, lambda u: u.login_count), transform=literal(1)),\n        FieldSpec(selector=field_of(User, lambda u: u.tags), transform=literal(\"beta\")),\n    ],\n    builder=PydanticBuilder(User),\n)\nmapping = MappingSpec(traversals=[\n    TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[emit]),\n    TraversalSpec(path=[\"users\"], mode=\"auto\", emits=[emit2]),\n])\n\nres = run_mapping(root, mapping)\nu = list(res[\"users\"].instances.values())[0]\nprint(u.login_count, u.tags)\n\n2 ['alpha', 'beta']\n\n\n\n\nBehavior and caveats\n\nPolicies are applied during update time per key/field.\nType mismatches are recorded as update errors; the row continues.\nDeterministic ordering follows traversal arrival order.\n\nFor more on how errors are reported, see Error reporting.\n\n\nSee also\n\nInstance emission - Where merge policies are used\nError reporting - How merge policy errors are reported"
  }
]